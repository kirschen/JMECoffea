{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import time\n",
    "import copy\n",
    "import scipy.stats as ss\n",
    "from scipy.optimize import curve_fit\n",
    "from coffea import hist, processor, nanoevents, util\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.nanoevents import NanoAODSchema, BaseSchema\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from dask.distributed import Client\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoffeaJERCProcessor import Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UsingDaskExecutor = True\n",
    "CoffeaCasaEnv     = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume running on the LPC\n",
    "xrootdstr = 'root://cmsxrootd.fnal.gov/'\n",
    "\n",
    "# if running on coffea casa instead...\n",
    "if CoffeaCasaEnv:\n",
    "    xrootdstr = 'root://xcache/'\n",
    "\n",
    "rootfiles = open('dataset.txt').read().split()\n",
    "\n",
    "fileslist = [xrootdstr + file for file in rootfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test on one file, uncomment the line below\n",
    "fileslist = [fileslist[0]]\n",
    "fileslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Setup:\n",
    "---\n",
    "### For Coffea-Casa, the client must be specified according to the user that is logged into the Coffea-Casa Environment.\n",
    "#### 1.) go to the left of this coffea-casa session to the task bar and click the orange-red button; it will say \"Dask\" if you hover your cursor over it\n",
    "#### 2.) scroll down to the blue box where it shows the \"Scheduler Address\"\n",
    "#### 3.) write that full address into the dask Client function \n",
    "#### Example: `client = Client(\"tls://ac-2emalik-2ewilliams-40cern-2ech.dask.coffea.casa:8786\")`\n",
    "---\n",
    "### For CMSLPC, the client must be specified with the LPCCondorCluster\n",
    "#### 1.) follow installation instructions from https://github.com/CoffeaTeam/lpcjobqueue, if you have not already done so, to get a working singularity environment with access to lpcjobqueue and LPCCondorCluster class\n",
    "#### 2.) import LPCCondorCluster: `from lpcjobqueue import LPCCondorCluster`\n",
    "#### 3.) define the client\n",
    "#### Example: \n",
    "`cluster = LPCCondorCluster()`\n",
    "\n",
    "`client = Client(cluster)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask set up for Coffea-Casa only\n",
    "if(UsingDaskExecutor and CoffeaCasaEnv):\n",
    "    client = Client(\"tls://ac-2emalik-2ewilliams-40cern-2ech.dask.coffea.casa:8786\")\n",
    "    client.upload_file('CoffeaJERCProcessor.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask set up for LPC only \n",
    "if(UsingDaskExecutor and not CoffeaCasaEnv):\n",
    "    from lpcjobqueue import LPCCondorCluster\n",
    "    cluster = LPCCondorCluster()\n",
    "    cluster.adapt(minimum=1, maximum=10)\n",
    "    client = Client(cluster)\n",
    "    client.upload_file('CoffeaJERCProcessor.py')\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "outputs_unweighted = {}\n",
    "\n",
    "seed = 1234577890\n",
    "prng = RandomState(seed)\n",
    "Chunk = [10000, 5] # [chunksize, maxchunks]\n",
    "\n",
    "# xrootdstr = 'root://cmsxrootd.fnal.gov/'\n",
    "# files = [xrootdstr + \"/store/mc/RunIISummer19UL17NanoAOD/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/JMECustomTuples_106X_mc2017_realistic_v6-v1/280000/0F7E67F1-5FCB-EC4B-A0B3-E0E9B98AFC43.root\"]\n",
    "# files = ['JMECustomTuples_106X_mc2017_realistic_v6-v1.root']\n",
    "\n",
    "filesets = {'QCD': fileslist}\n",
    "\n",
    "for name,files in filesets.items(): \n",
    "    if not UsingDaskExecutor:\n",
    "        chosen_exec = 'futures'\n",
    "        output = processor.run_uproot_job({name:files},\n",
    "                                          treename='Events',\n",
    "                                          processor_instance=Processor(),\n",
    "                                          executor=processor.iterative_executor,\n",
    "    #                                        executor=processor.futures_executor,\n",
    "                                          executor_args={\n",
    "                                              'skipbadfiles':False,\n",
    "                                              'schema': NanoAODSchema, #BaseSchema\n",
    "                                              'workers': 2},\n",
    "                                          chunksize=Chunk[0])#, maxchunks=Chunk[1])\n",
    "    else:\n",
    "        chosen_exec = 'dask'\n",
    "        output = processor.run_uproot_job({name:files},\n",
    "                                          treename='Events',\n",
    "                                          processor_instance=Processor(),\n",
    "                                          executor=processor.dask_executor,\n",
    "                                          executor_args={\n",
    "                                              'client': client,\n",
    "                                              'skipbadfiles':False,\n",
    "                                              'schema': NanoAODSchema, #BaseSchema\n",
    "#                                               'workers': 2\n",
    "                                          },\n",
    "                                          chunksize=Chunk[0])#, maxchunks=Chunk[1])\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "outputs_unweighted[name] = output\n",
    "print(output)\n",
    "util.save(output, 'CoffeaJERCOutputs_casa.coffea')\n",
    "\n",
    "\n",
    "outputs_unweighted[name] = output\n",
    "print(name + ' unweighted output loaded')\n",
    "elapsed = time.time() - tstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load coffea output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = util.load('CoffeaJERCOutputs_19928000events.coffea')\n",
    "# output = util.load('CoffeaJERCOutputs_binned.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gaussian function\n",
    "def gauss(x, *p):\n",
    "    A, mu, sigma = p\n",
    "    return A*np.exp(-(x-mu)**2/(2.*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbins = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 23, 27, 30, 35, 40, 45, 57, 72, 90, 120, \n",
    "        150, 200, 300, 400, 550, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 10000 ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etabins =   [-4.889,  -4.716,  -4.538,  -4.363,  -4.191,  -4.013,  -3.839,  -3.664,  -3.489,\n",
    "           -3.314,  -3.139,  -2.964,  -2.853,  -2.65,  -2.5,  -2.322,  -2.172,  -2.043,  -1.93,  -1.83,\n",
    "           -1.74,  -1.653,  -1.566,  -1.479,  -1.392,  -1.305,  -1.218,  -1.131,  -1.044,  -0.957,  -0.879,\n",
    "           -0.783,  -0.696,  -0.609,  -0.522,  -0.435,  -0.348,  -0.261,  -0.174,  -0.087,  0,  0.087,  0.174,\n",
    "           0.261,  0.348,  0.435,  0.522,  0.609,  0.696,  0.783,  0.879,  0.957,  1.044,  1.131,  1.218,\n",
    "           1.305,  1.392,  1.479,  1.566,  1.653,  1.74,  1.83,  1.93,  2.043,  2.172,  2.322,  2.5,  2.65,\n",
    "           2.853,  2.964,  3.139,  3.314,  3.489,  3.664,  3.839,  4.013,  4.191,  4.363,  4.538,  4.716,\n",
    "           4.889, ]#5.191 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetpt_length = len(output['jetpt'].axis('pt')[1:-1])\n",
    "jeteta_length = len(output['jeteta'].axis('jeteta')[1:-1])\n",
    "jeteta_length = len(etabins)\n",
    "\n",
    "mean = np.zeros((jetpt_length, jeteta_length))\n",
    "median = np.zeros((jetpt_length, jeteta_length))\n",
    "width = np.zeros((jetpt_length, jeteta_length))\n",
    "idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(etabins)-1):\n",
    "    print(hist.Interval(etabins[k], etabins[k+1]))\n",
    "print()    \n",
    "for k, etaBin in enumerate(output['jeteta'].axis('jeteta')[1:-1]):\n",
    "    print(etaBin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xvals = output['ptresponse'].axis('ptresponse').centers()\n",
    "f_xvals = np.linspace(0,5,5001)\n",
    "\n",
    "# mean = [[]]*len(output['jetpt'].axis('pt')[1:-1])\n",
    "# median = [[]]*len(output['jetpt'].axis('pt')[1:-1])\n",
    "# width = [[]]*len(output['jetpt'].axis('pt')[1:-1])\n",
    "# idx = []\n",
    "\n",
    "j = 0\n",
    "\n",
    "# for i, ptBin in enumerate(output['jetpt'].axis('pt')[1:-1]):\n",
    "    \n",
    "for i in range(len(ptbins)-1):\n",
    "        \n",
    "    ptBin = hist.Interval(ptbins[i], ptbins[i+1])\n",
    "    print('pt bin '+str(ptBin))\n",
    "    \n",
    "    if not 'inf' in str(ptBin):\n",
    "        pt_string = '_pT'+str(int(ptBin.lo))+'to'+str(int(ptBin.hi))\n",
    "    else:\n",
    "        pt_string = '_pT'+str(ptBin.lo) + 'to' + str(ptBin.hi)\n",
    "        pt_string = pt_string.replace('.0','').replace('-infto','0to')\n",
    "    \n",
    "#     for k, etaBin in enumerate(output['jeteta'].axis('jeteta')[1:-1]):\n",
    "    for k in range(len(etabins)-1):\n",
    "        \n",
    "        etaBin = hist.Interval(etabins[k], etabins[k+1])\n",
    "        \n",
    "    \n",
    "        \n",
    "        eta_string = '_eta'+str(etaBin.lo)+'to'+str(etaBin.hi)\n",
    "        eta_string = eta_string.replace('.','')\n",
    "\n",
    "        \n",
    "        \n",
    "        histo = output['ptresponse'].integrate('jeteta', etaBin).integrate('pt', ptBin)\n",
    "        \n",
    "        histvals = np.repeat(histo.axis('ptresponse').centers(), np.array(histo.values()[('QCD',)],dtype='int'))\n",
    "\n",
    "        yvals = histo.values()[('QCD',)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            p, arr = curve_fit(gauss, xvals, yvals, p0=[10,1,1])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        fgaus = gauss(f_xvals, *p)\n",
    "        \n",
    "#         median[i,k] = f_xvals[fgaus == np.max(fgaus)]\n",
    "        median[i,k] = np.median(histvals)\n",
    "        mean[i,k] = p[1]\n",
    "        width[i,k] = p[2]\n",
    "        idx.append(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "#         h = np.max(histo.values()[('QCD',)])\n",
    "#         ax = hist.plot1d(histo, overlay='dataset')\n",
    "# #         plt.plot(f_xvals, fgaus)\n",
    "#         plt.text(4,0.75*h,'Mean {0:0.2f}'.format(p[1]))\n",
    "#         plt.text(4,0.7*h,'Median {0:0.2f}'.format(np.median(histvals)))\n",
    "#         plt.text(4,0.65*h,'Width {0:0.2f}'.format(p[2]))\n",
    "\n",
    "\n",
    "#         plt.savefig('ptResponse'+pt_string+eta_string+'.png')\n",
    "#         plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo = output['ptresponse'].integrate('jeteta', hist.Interval(-0.5, 0)).integrate('pt', hist.Interval(180, 200))\n",
    "\n",
    "histo.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        h = np.max(histo.values()[('QCD',)])\n",
    "        ax = hist.plot1d(histo, overlay='dataset')\n",
    "#         plt.plot(f_xvals, fgaus)\n",
    "        plt.savefig('ptResponse'+pt_string+eta_string+'.png')\n",
    "        plt.text(4,0.75*h,'Mean {0:0.2f}'.format(p[1]))\n",
    "        plt.text(4,0.7*h,'Median {0:0.2f}'.format(np.median(histvals)))\n",
    "        plt.text(4,0.65*h,'Width {0:0.2f}'.format(p[2]))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {str(ptBin):mean[i] for i, ptBin in enumerate(output['jetpt'].axis('pt')[1:-1])}\n",
    "data = {str(ptBin):mean[i] for i, ptBin in enumerate(ptbins)}\n",
    "\n",
    "# data['etaBins'] = [str(etaBin) for etaBin in output['jeteta'].axis('jeteta')[1:-1]]\n",
    "data['etaBins'] = [str(etaBin) for etaBin in etabins]\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df.set_index('etaBins')\n",
    "df.to_csv('EtaBinsvsPtBinsMean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_width = {str(ptBin):width[i] for i, ptBin in enumerate(output['jetpt'].axis('pt')[1:-1])}\n",
    "data_width = {str(ptBin):width[i] for i, ptBin in enumerate(ptbins)}\n",
    "\n",
    "# data_width['etaBins'] = [str(etaBin) for etaBin in output['jeteta'].axis('jeteta')[1:-1]]\n",
    "data_width['etaBins'] = [str(etaBin) for etaBin in etabins]\n",
    "\n",
    "df_width = pd.DataFrame(data=data_width)\n",
    "df_width = df_width.set_index('etaBins')\n",
    "df_width.to_csv('EtaBinsvsPtBinsWidth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_median = {str(ptBin):median[i] for i, ptBin in enumerate(output['jetpt'].axis('pt')[1:-1])}\n",
    "data_median = {str(ptBin):median[i] for i, ptBin in enumerate(ptbins)}\n",
    "\n",
    "# data_median['etaBins'] = [str(etaBin) for etaBin in output['jeteta'].axis('jeteta')[1:-1]]\n",
    "data_median['etaBins'] = [str(etaBin) for etaBin in etabins]\n",
    "\n",
    "df_median = pd.DataFrame(data=data_median)\n",
    "df_median = df_median.set_index('etaBins')\n",
    "df_median.to_csv('EtaBinsvsPtBinsMedian.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[pt bin][eta bin]\n",
    "\n",
    "ptBin = '300'\n",
    "etaBin = '0.783'\n",
    "\n",
    "print('mean   =', np.round(df[ptBin][etaBin],3))\n",
    "print('median =', np.round(df_median[ptBin][etaBin],3))\n",
    "print('width  =', np.round(df_width[ptBin][etaBin],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[pt bin][eta bin]\n",
    "\n",
    "ptBin = '300'\n",
    "etaBin = '0.783'\n",
    "\n",
    "print('mean   =', df[ptBin][etaBin])\n",
    "print('median =', df_median[ptBin][etaBin])\n",
    "print('width  =', df_width[ptBin][etaBin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "format for example $ 20 \\text{ GeV} < p_T < 25 \\text{ GeV} $ and $ 3.5 < \\eta < 4.0 $\n",
    "\n",
    "\n",
    "```\n",
    "df = pd.read_csv('EtaBinsvsPtBinsMean.csv).set_index('etaBins')\n",
    "ptBin='[20, 25)'\n",
    "etaBin='[3.5, 4)'\n",
    "mean = df[ptBin][etaBin]\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('EtaBinsvsPtBinsMean.csv').set_index('etaBins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
